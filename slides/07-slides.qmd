---
title: "POLS 1600"
subtitle: "Interpreting and Evaluating<br>Linear Models"
date: last-modified
date-format: "[Updated ]MMM D, YYYY"
format: 
  revealjs:
    theme: brownslides.scss
    logo: images/pols1600_hex.png
    footer: "POLS 1600"
    multiplex: false
    transition: fade
    slide-number: c
    incremental: true
    center: false
    menu: true
    scrollable: true
    highlight-style: github
    progress: true
    html-math-method: mathjax
    code-overflow: wrap
    chalkboard: true
    # include-after-body: title-slide.html
    title-slide-attributes:
      align: left
      data-background-image: images/pols1600_hex.png
      data-background-position: 90% 50%
      data-background-size: 40%
filters:
  - openlinksinnewpage
execute: 
  eval: true
  echo: true
  warning: false
  message: false
  cache: false
---


```{r}
#| label: init
#| echo: false
#| results: hide
#| warning: false 
#| message: false

library(tidyverse)
library(labelled)
library(haven)
library(DeclareDesign)
library(easystats)
library(texreg)

```



# {{< fa map-location>}} Overview {.inverse}

## Class Plan

- Announcements (2-3 min)
- Setup (2-3 min)
- Feedback (15 min)
- Topics:
  - What does it mean to control for X
  - How to make predictions with regression
  - Evaluating model fit
  - Difference-in-Differences
  - Set up for Lab 7

## Goals

- Regression models [partition variation]{.blue} in an outcome into variation explained by the model and not explained by the model

- Individual regression coefficients reflect the [variation explained by that predictor]{.blue}, and [only that predictor]{.blue}

- [Predicted values]{.blue} for regression models aid in [substantive interpretation]{.blue}

- [Measures of model fit]{.blue} like $R^2$ can be useful for comparing different regression models

- [Difference-in-differences]{.blue} designs combine [pre-post]{.blue} and [treatment-control]{.blue} comparisons to make [stronger causal claims]{.blue}.

## Annoucements

- [Assignment 1: Research Questions](https://pols1600.paultesta.org/assignments/a1) Feedback end of today
  - Feedback by class on Thursday
- [Assignment 2  Data:](https://pols1600.paultesta.org/assignments/a2) due Friday March 22

## Setup: Packages for today

```{r}
#| label: packages
#| echo: true

## Pacakges for today
the_packages <- c(
  ## R Markdown
  "kableExtra","DT","texreg","htmltools",
  ## Tidyverse
  "tidyverse", "lubridate", "forcats", "haven", "labelled",
  ## Extensions for ggplot
  "ggmap","ggrepel", "ggridges", "ggthemes", "ggpubr", 
  "GGally", "scales", "dagitty", "ggdag", "ggforce",
  # Data 
  "COVID19","maps","mapdata","qss","tidycensus", "dataverse", 
  # Analysis
  "DeclareDesign", "easystats", "zoo"
)

## Define a function to load (and if needed install) packages

ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

## Install (if needed) and load libraries in the_packages
ipak(the_packages)
```


## Feedback {.center}

```{r}
#| label: feeback
#| echo: false
df <- haven::read_spss("../files/data/class_surveys/wk06.sav")


df %>%
  mutate(
    `Comparison Includes`= ifelse(is.na(eval_1), "Trump", "No Trump"),
    You = ifelse(is.na(eval_1), eval_trump_1, eval_1),
    Me = ifelse(is.na(eval_2), eval_trump_2, eval_2),
    Trump = eval_trump_6,
    `Everyone we know` = ifelse(is.na(eval_3), eval_trump_3, eval_3),
  ) -> df

```


## What did we like {.smaller}

```{r}
#| label: likes
#| echo: false
DT::datatable(df %>% 
                select(Likes),
               fillContainer = F,
              height = "90%",
              options = list(
                pageLength = 5
              )
              )
```

## What did we dislike {.smaller}

```{r}
#| label: dislikes
#| echo: false

DT::datatable(df %>% 
                select(Dislikes),
               fillContainer = F,
              height = "90%",
              options = list(
                pageLength = 5
              )
              )
```

## What we're good at{.smaller}

```{r}
#| echo: false
DT::datatable(df %>% 
                select(code_skills),
               fillContainer = F,
              height = "90%",
              options = list(
                pageLength = 5
              )
              )
```

## What we're working on{.smaller}

```{r}
#| echo: false
DT::datatable(df %>% 
                select(code_challenge),
               fillContainer = F,
              height = "90%",
              options = list(
                pageLength = 5
              )
              )
```

## How are we doing?

```{r}
#| label: howwedoing
#| echo: false 

df %>% 
ggplot(aes(You, Me))+
  geom_point()+
  geom_abline(slope = 1, intercept = 0)+
  ylim(0,100)+
  xlim(0,100) -> fig1eval

df %>% 
ggplot(aes(You, `Everyone we know`))+
  geom_point()+
  geom_abline(slope = 1, intercept = 0)+
  ylim(0,100)+
  xlim(0,100) -> fig2eval

ggarrange(fig1eval, fig2eval)
```

## Don't trust the polls

```{r}
#| label: figtrump
#| echo: false
df %>% 
  ggplot(aes(`Comparison Includes`, Me))+
  stat_summary(
  ) +
  theme_minimal()+
  labs(
    title = "Difference in average evaluation when:"
  )
```


##

```{r}
#| echo: false
df %>%
  mutate(
    `Comparison Includes`= ifelse(is.na(eval_1), "Trump", "No Trump"),
    You = ifelse(is.na(eval_1), eval_trump_1, eval_1),
    Me = ifelse(is.na(eval_2), eval_trump_2, eval_2),
    Trump = eval_trump_6,
    `Everyone we know` = ifelse(is.na(eval_3), eval_trump_3, eval_3),
  )%>%
  select(`Comparison Includes`, Me, You, `Everyone we know`, Trump)%>%
  pivot_longer(
    cols = -`Comparison Includes`,
    names_to = "Target",
    values_to = "Evaluation"
      
  )%>%
  mutate(
    Target = factor(Target, levels = rev(c("You","Me", "Everyone we know", "Trump")))
  )%>%
  ggplot(aes(Evaluation, Target, fill=`Comparison Includes`))+
  geom_density_ridges(
                      jittered_points = TRUE,
                      position = position_points_jitter(width = 0.05, height = 0),
                      point_shape = '|', point_size = 3, point_alpha = 1, alpha = 0.7,
                      )+
  labs(y="",
       title = "How are we doing?")
```

## What should we do going forward?

- From me:
  - Shorter labs
  - Shorter slides
  - More coding, less copy-pasting 

- From you?


# {{< fa lightbulb >}} What does it mean to "control for X" {.inverse}

## Regression models partition variance {.smaller}

Regression models [partition variance]{.blue}, separating the [variation in the outcome]{.blue} **into** [variation explained by the predictors]{.blue} in our model and the [remaining variation not explained]{.blue} by these predictors

$$\begin{aligned}
\textrm{Total Variance} &= \textrm{Variance Explained by Model} + \textrm{Unexplained Variance} \\
\textrm{Observed} &= \textrm{Predicted Value} + \textrm{Error}\\
\textrm{Y} &=  E[Y|X] + \epsilon\\
\textrm{Y} &=  X\hat{\beta} + \hat{\epsilon}\\
\textrm{Y} &= \hat{Y} + \hat{\epsilon}
\end{aligned}$$

## {.smaller}
#### Coefficients describe the unique variance in Y explained by X (and only X)

::: panel-tabset

## Task

The coefficients in a regression model describe the variation in the outcome explained by that predictor, and only that predictor.

Let's fit three models from last week's lab and look at how the coefficients change from model to model

## {{< fa code >}}
```{r}
#| label: labmodels
load(url("https://pols1600.paultesta.org/files/data/06_lab.rda"))
m1 <- lm(new_deaths_pc_14day ~ rep_voteshare_std, covid_lab)
m2 <- lm(new_deaths_pc_14day ~ rep_voteshare_std + med_age_std, covid_lab)
m3 <- lm(new_deaths_pc_14day ~ rep_voteshare_std + med_age_std + med_income_std, covid_lab)

```

## {{< fa table >}}

```{r}
#| label: labtab

htmlreg(list(m1, m2, m3)) %>% HTML() %>% browsable()

```

:::


## Why do coefficients change when we control for variables?{.center}


## Residualized Regression


Residualized regression is way of understanding what it means to [control for variables]{.blue} in a regression.

Residualized regression provides a way of illustrating what we mean when say the coefficients describe the unique variance in Y explained by some predictor $x$ (and only $x$)


## What's a residual


- [Residuals]{.blue} represent the part of the outcome variable, [not explained]{.blue} by the predictors in a model
  - Difference between the observed $y$ and the predicted $\hat{y}$
  

$$y = \overbrace{\beta_0 + \beta_1x_1 + \beta_2 x_2  + \dots \beta_j x_j}^{\text{Predictors}} + \underbrace{\epsilon}_{\text{Residuals}}$$

## Residuals are uncorrelated with $X$ and $\hat{y}${.smaller}

::::{.columns}

:::{.column width=40%}

Residuals are uncorrelated with (orthogonal to) the predictors $X$, and predicted values $X\beta$

```{r}
#| label: rescor

# Trust but verify
cor(resid(m2),covid_lab$rep_voteshare_std) 
cor(resid(m2),covid_lab$med_age_std)
cor(resid(m2),fitted(m2))
```


:::

:::{.column width=55%}

![](https://www.researchgate.net/publication/299483509/figure/fig1/AS:992683870937088@1613685686096/llustration-of-the-linear-regression-model-as-a-projection-method.png)

:::

::::

## {.smaller}
#### Residualized Regression 


:::: panel-tabset

## {{< fa lightbulb >}}

:::{.nonincremental}

For a model like `m2` we can recover the coefficient on `rep_voteshare_std` by:
  
1. Regressing `new_deaths_pc_14day` on `med_age_std` to get the [residual]{.blue} variation in Covid-19 deaths [not explained]{.blue} by median age 
2. Regressing `rep_voteshare_std` on `med_age_std` to get the [residual]{.blue} variation in Republican Vote Share [not explained]{.blue} by median age 
3. Regressing the residuals from 1. (Deaths not explained by age) on the residuals from 2. (Vote share not explained by age) to obtain the [same]{.blue} coefficient from `m2` for `rep_voteshare_std`

The same principle holds for `m3`

:::

## {{< fa code >}} m2

```{r}
#| label: resm2

# 1. Regressing `new_deaths_pc_14da` on `med_age_std`
m2_death_by_age <- lm(new_deaths_pc_14day ~ med_age_std, covid_lab)
# Save residuals
covid_lab$res_death_no_age <- resid(m2_death_by_age)

# 2. Regressing `rep_voteshare_std` on `med_age_std` 
m2_repvs_by_age <- lm(rep_voteshare_std ~ med_age_std, covid_lab)
# Save residuals
covid_lab$res_repvs_no_age <- resid(m2_repvs_by_age)

# 3. Residualized regression of deaths on Rep Vote Share
m2_res <- lm(res_death_no_age ~ res_repvs_no_age, covid_lab)

# Mutliple regression
coef(m2)[2]

# Residualized regression
coef(m2_res)[2]
```

## {{< fa code >}} m3

```{r}
#| label: resm3

# 1. Regressing `new_deaths_pc_14da` on `med_age_std` and med_income_std
m3_death_by_age_income <- lm(new_deaths_pc_14day ~ med_age_std + med_income_std, covid_lab)
# Save residuals
covid_lab$res_death_no_age_income <- resid(m3_death_by_age_income)

# 2. Regressing `rep_voteshare_std` on `med_age_std` and med_income_std
m3_repvs_by_age_income <- lm(rep_voteshare_std ~ med_age_std + med_income_std, covid_lab)
# Save residuals
covid_lab$res_repvs_no_age_income <- resid(m3_repvs_by_age_income)

# 3. Residualized regression of deaths on Rep Vote Share
m3_res <- lm(res_death_no_age_income ~ res_repvs_no_age_income, covid_lab)

# multiple regression coefficient
coef(m3)[2]
# Same as  residualized regression coefficient
coef(m3_res)[2]
```
::::

## Why did the coefficient on Rep Vote Share change in `m3` but not `m2`?{.center}

## {.smaller}

## {.smaller}

```{r}
#| label: ivtab1
#| echo: false
htmlreg(list(m1),
          custom.model.names = c("Baseline"),
        custom.header = list("DV: Death"=1)
        ) %>% HTML() %>% browsable()
```

##

$$
\text{Covid-19 Deaths} = \beta_0 + \beta_1 \text{Rep Vote Share}
$$

```{r}
#| label: venn_iv1
#| echo: false

# Colors (order: x1, x2, x3, y, z)
venn_colors <- c("grey", "blue", "grey", "red")
venn_lab_colors <- c("white", "blue", "white", "red")

# Line types (order: x1, x2, x3, y, z)
venn_lines <- c("solid", "solid", "solid", "solid")
# Locations of circles
venn_df <- tibble(
  x  = c( 0.0,   0,    1.3,    -2),
  y  = c( 0.0,   -2.5,   -1.8,    -2.8)+1,
  r  = c( 1.9,    1.5,    1.5,      1.3),
  l  = c( "Deaths", "RepVS", "Income",   "Age"),
  cc = c("grey", "red", "black", "blue"),
  lc = c( "red", "blue", "white","white"),
  xl = c( 0.0,    0,    1.3,  -2),
  yl = c( 0.0,   -2.8,   -1.9,   -2.8)+1,
  a = c(.3, .3 , .7, .7)
)

# Venn
venn_df %>%
  filter(l %in% c( "Deaths", "RepVS")) %>%
ggplot(aes(x0 = x, y0 = y, r = r, fill = l, color = l)) +
geom_circle(aes(linetype = l, alpha = a), size = 0.75) +
theme_void() +
theme(legend.position = "none") +
scale_fill_manual(values = venn_colors[c(4,2)]) +
scale_color_manual(values = venn_colors[c(4,2)]) +
scale_linetype_manual(values = venn_lines) +
geom_text(aes(x = xl, y = yl, label = l), col=c("red","blue"), size = 9, parse = T ) +
annotate(
  x = 0, y = -0.5,
  geom = "text", label = expression(beta[1]), size = 10, hjust = .5
) +
xlim(-5.5, 4.5) +
ylim(-4.2, 3.4) +
coord_equal()
```

## {.smaller}

```{r}
#| label: ivtab2
#| echo: false

htmlreg(list(m1,m2, m2_death_by_age,m2_repvs_by_age, m2_res),
        custom.model.names = c("Baseline","Mutliple","Age","Vote Share","Deaths"),
        custom.header = list("DV: Death"=1:3, "DV: Vote Share"=4, "DV: Res. Deaths"=5)) %>% HTML() %>% browsable()
```


##

$$
\text{Deaths} = \beta_0 + \beta_1 \text{Rep VS} + \beta_2 \text{Age}
$$

```{r}
#| label: venn_iv2
#| echo: false

#| echo = F
venn_df %>%
  filter(l %in% c( "Deaths", "RepVS","Age")) %>%
ggplot(aes(x0 = x, y0 = y, r = r, fill = l, color = l)) +
geom_circle(aes(linetype = l, alpha = a), size = 0.75) +
theme_void() +
theme(legend.position = "none") +
scale_fill_manual(values = venn_colors[c(1,2,4)]) +
scale_color_manual(values = venn_colors[c(1,2,4)]) +
scale_linetype_manual(values = venn_lines) +
geom_text(aes(x = xl, y = yl, label = l), col=c("blue","red","white"), size = 9, parse = T ) +
annotate(
  x = 0, y = -.5,
  geom = "text", label = expression(beta[1]), size = 10, hjust = .5
) +
xlim(-5.5, 4.5) +
ylim(-4.2, 3.4) +
coord_equal()

```

$\beta_1$ doesn't change because `age` has no relationship to `deaths` in these data

## {.smaller}

```{r}
#| label: ivtab3
#| echo: false
htmlreg(list(m1, m3, m3_death_by_age_income, m3_repvs_by_age_income,m3_res),
          custom.model.names = c("Baseline","Full","No Rep","Vote Share","Deaths"),
        custom.header = list("DV: Death"=1:3, "DV: Vote Share"=4, "DV: Res. Death"=5)
        ) %>% HTML() %>% browsable()
```


##

$$
\text{Deaths} = \beta_0 + \beta_1 \text{Rep VS} + \beta_2 \text{Age} + \beta_3 \text{Income}
$$

```{r}
#| label: venn_iv3
#| echo: false

venn_df %>%
ggplot(aes(x0 = x, y0 = y, r = r, fill = l, color = l)) +
geom_circle(aes(linetype = l, alpha = a), size = 0.75) +
theme_void() +
theme(legend.position = "none") +
scale_fill_manual(values = venn_colors) +
scale_color_manual(values = venn_colors) +
scale_linetype_manual(values = venn_lines) +
geom_text(aes(x = xl, y = yl, label = l), col=c("blue","red","white","white"), size = 9, parse = T ) +
annotate(
  x = -0.45, y = -.45,
  geom = "text", label = expression(beta[1]), size = 5, hjust = .5
) +
xlim(-5.5, 4.5) +
ylim(-4.2, 3.4) +
coord_equal()
```

$\beta_1$ decreases because after controlling for `income` there is less unique variation explained only by `republican vote share`


# {{< fa lightbulb >}} Using regression to make predictions {.inverse}

## Using regression to produce predicted values {.smaller}

Coefficients in a regression define a formula which produces a predicted value of the outcome $y$ when the predictors $X$ take particular values.

$$
\begin{aligned}y &= \overbrace{\beta_0 + \beta_1x_1 + \beta_2 x_2  + \dots \beta_j x_j}^{\text{Predictors}} + \underbrace{\epsilon}_{\text{Residuals}} &\\
y &= \beta_0 + \beta_1x_{rvs} + \beta_2x_{age}+ \beta_3x_{inc} + \epsilon & \text{m3}\\
y &= 0.56 + 0.07x_{rvs} - 0.02 x_{age} - 0.22 x_{inc} + \hat{\epsilon} & \text{estimated m3}\\
y &= 0.56 + 0.07(-0.87) - 0.02(0.62) - 0.22(0.38) + \hat{\epsilon} & \text{prediction for RI} \\
\overbrace{0.22}^{\text{Observed}} &= \underbrace{0.41}_{\text{Predicted}} + \overbrace{(-0.19)}^{\text{Residual}} &
\end{aligned}
$$

## Producing Predicted Values in R {.smaller}

The basic steps to producing predicted values in R as follows:

- Fit a model using `lm()`
- Create a [prediction data frame]{.blue} using `expand_grid()`:
  - [vary]{.blue} the values of [the predictor]{.blue} you're interested in
  - [hold]{.blue} all the other predictors in your model [constant]{.blue} at some typical value.
- Input the [model]{.blue} from `lm()` and the [prediction data frame]{.blue}, into the `predict()` function to obtain [predicted values]{.blue}. 
  - Save predictions as a new column in your [prediction data frame]{.blue} (I generally call them `fit`)
- Plot predicted values in your [prediction data frame]{.blue} to help interpret your model

## {.smaller}
#### Are there decreasing returns to vaccination?

:::: panel-tabset

## Task

Suppose we thought the [marginal effect]{.blue} -- (here, predicted change in deaths from a 1 percent increase in the percent of the population vaccinated) of vaccines varied.

There might be large gains from going to low to average rates of vaccination, but after a certain threshold, the decreases in deaths would taper off.

We could test this by including a [polynomial term]{.blue} `I(percent_vaccinated)^2` in our model.

Including a polynomial term, allows the marginal effect to vary, based on the value of the predictor.

It's hard to interpret the coefficients on [polynomial terms]{.blue} (or interaction terms) just by looking at coefficients in a table

Instead, we'll produce a plot of predicted values to test these claims

## {{<fa code >}} m4

```{r}
m4 <- lm(new_deaths_pc_14day ~ percent_vaccinated + I(percent_vaccinated^2) + rep_voteshare_std + med_age_std + med_income_std, covid_lab
           )
```

## {{<fa table >}} Table

```{r}
#| label: tabm4
#| echo: false
#| results: asis
htmlreg(m4, digits = 3)
```

## {{<fa code >}} Predict

```{r}
#| label: predm4

pred_df <- expand_grid(
  percent_vaccinated = sort(unique(covid_lab$percent_vaccinated)),
  # Set standardized predictors to their means of 0
  rep_voteshare_std = 0,
  med_age_std = 0,
  med_income_std = 0
)

pred_df$fit <- predict(m4, newdata = pred_df)

pred_df %>% 
  ggplot(aes(percent_vaccinated, fit))+
  geom_line()+
  labs(
    y = "Predicted Covid-19 Deaths\n(per capita, 14-day average)",
    x = "Percent of State's population that's Vaccinated"
  ) + 
  theme_minimal() -> fig_m4
```


## {{<fa chart-line>}} Fig

For a typical state, early increases in vaccination rate are associated with larger declines in predicted deaths from Covid-19

```{r}
#| echo: false

fig_m4
```


::::


# {{< fa lightbulb >}} Evaluating Model Fit {.inverse}

## Evaluating Model Fit

Models partition variance. We can summarize the overall fit of our model using measures like $R^2$

$$R^2 = \frac{\text{variance(predicted values )}}{ \text{variance(observed values )}}$$

## R^2

More formally, you'll see $R^2$ defined in terms of "Sums of Squares"

- TSS = [Total Sum of Squares]{.blue} = Variance of the Outcome
- ESS = [Explained Sum of Squares]{.blue} = Variance of the Predicted Values
- RSS = [Sum of Squared Residuals]{.blue} = Variance of the Residuals

$$R^2 = \frac{ESS}{TSS}= 1 - \frac{RSS}{TSS}$$

## Calculating $R^2$ in R{.smaller}

We could do it by hand, finding that our model explained about 43 percent of the observed variation deaths.

```{r}
# ESS / TSS
var(m3$fitted.values)/var(m3$model$new_deaths_pc_14day)
# 1 - RSS/TSS
1 - var(m3$residuals)/var(m3$model$new_deaths_pc_14day)

```

But generally we let the `summary()` function do it for us:

```{r}
summary(m3)
```


## Adjusted $R^2${.smaller}

:::: panel-tabset

## Adjusted $R^2$

:::{.nonincremental}
- One can show that a models $R^2$ [always increases]{.blue} as we [add predictors]{.blue}, even when they're unrelated to the outcome

- The [adjusted $R^2$]{.blue} adjusts for this by weighting the $R^2$ of a model by the number of predictors

$$\text{adj. }R^2 = 1 - \frac{RSS/(n-k)}{TSS/(n-1)}$$

:::

## {{< fa code >}} Example

```{r}

ex_df <- data.frame(
  y = rnorm(100) 
  ) %>%
    bind_cols(
      data.frame(matrix(rnorm(10000), ncol=100))
    ) %>% janitor::clean_names()


the_formulas <- list()
for(i in 2:51){
  vars <- names(ex_df)[2:i]
  the_formulas[[i-1]] <- paste("y~",paste(vars,collapse = "+"))
}

the_formulas %>% 
  purrr::map(as.formula) %>% 
  purrr::map(lm, data=ex_df) %>% 
  purrr::map(summary) %>% 
  purrr::map_df(glance) -> r2_df

r2_df %>% 
  ggplot(aes(df, r.squared))+
  geom_point(aes(col = "R^2"))+
  geom_line()+
  geom_point(aes(y=adj.r.squared,col = "Adjusted R^2"))+
  geom_line(aes(y=adj.r.squared))+
  labs(
    x = "Number of predictors",
    y = "Proportion of Variance Explained",
    title = "Adding unrelated predictors increases a model's R^2\nwhile the Adjusted R^2 provides a better indicator of poor fit ",
    col ="Model fit"
  ) -> fig_r2






```

## {{< fa chart-line >}} Figure

```{r}
#| echo: false
fig_r2

```

::::

## {.smaller}
#### Using $R^2$ to compare models

::::panel-tabset

## ANOVA

When models are *nested* (larger models contain all the predictors of smaller models), we can ask, does including the additional predictors in the larger model explain more variation in the outcome than we would expect would happen if we just added additional, random variable.

Formally we call this process an [Analysis of Variance (ANOVA)](https://towardsdatascience.com/anova-for-regression-fdb49cf5d684#:~:text=It%20is%20the%20same%20as,or%20more%20categorical%20predictor%20variables.)

Let's assess the added predictive power of `I(percent_vaccinated^2)` by estimating a model without it and comparing models using ANOVA 

## {{<fa code >}} m5

```{r}
# Estimate model without polynomial
m5 <- lm(new_deaths_pc_14day ~ percent_vaccinated  + rep_voteshare_std + med_age_std + med_income_std, covid_lab
           )
```

## {{<fa table >}} Table

```{r}
#| label: tabm5
#| echo: false
#| results: asis
htmlreg(list(m4,m5), digits = 3)
```

## {{<fa code >}} Anova

The anova suggests that including a polynomial provides a *marginal* improvement to fit (p < 0.10)

```{r}
anova(m5, m4)

```



::::


## {.smaller}
#### Standardized vs Non Standardized Predictors

::::panel-tabset

## {{<fa light-bulb>}}

Why are we using standardized predictors?

Standardizing variables is a common transformation:

$$z\text{-scores of x} = \frac{x_i - \mu_{x}}{\sigma_x}$$
When variables are measured on very different scales or units (e.g. age in years, income in dollars), using standardized (or normalized) versions rescales them to a unit-less measures that all have:

- a mean of `zero`
- a standard deviation of `1`


## {{<fa code >}} m6

```{r}
# Estimate model  with unstandardized predictors
m6 <- lm(new_deaths_pc_14day ~ percent_vaccinated  + rep_voteshare + med_age + med_income, covid_lab
           )
```

## {{<fa table >}} Table

```{r}
#| label: tabm6
#| echo: false
#| results: asis
htmlreg(list(m5, m6), digits = 3)
```

## {{<fa code >}} Comments

When should you standardize variables? It depends on what you're trying to do.

- It's the same information, just rescaled:

```{r}
coef(m5)[5] # Standardized coef
coef(m6)[5] # Unstandaried
coef(m6)[5]*sd(covid_lab$med_income) # Same as standardized
```


- Can facilitate comparison and estimation

- Might make interpretation easier (but the onus is on you to describe your models well)

  - Don't standardized binary predictors




::::

# {{< fa lightbulb >}} Difference-in-Differences {.inverse}

## Motivating Example: What causes Cholera? {.smaller background-image=https://www.finebooksmagazine.com/sites/default/files/styles/gallery_item/public/media-images/2020-11/map-lead-4.jpg?h=2ded5a3f&itok=Mn-K5rQc, background-opacity=.3}

- In the 1800s, cholera was thought to be transmitted through the air.

- John Snow (the physician, not the snack), to explore the origins eventunally concluding that cholera was transmitted through living organisms in water.

- Leveraged a **natural experiment** in which one water company in London moved its pipes further upstream (reducing contamination for Lambeth), while other companies kept their pumps serving Southwark and Vauxhall in the same location. 


## Notation {.smaller}

Let's adopt a little notation to help us think about the logic of Snow's design:

- $D$: treatment indicator, 1 for treated neighborhoods (Lambeth), 0 for control neighborhoods (Southwark and Vauxhall)

- $T$: period indicator, 1 if post treatment (1854), 0 if pre-treatment (1849).

- $Y_{di}(t)$ the potential outcome of unit $i$ 

  - $Y_{1i}(t)$ the potential outcome of unit $i$ when treated between the two periods 

  - $Y_{0i}(t)$ the potential outcome of unit $i$ when control between the two periods 


## Causal Effects {.smaller}

The individual causal effect for unit i at time t is:

$$\tau_{it} = Y_{1i}(t) − Y_{0i}(t)$$


What we observe is 

$$Y_i(t) = Y_{0i}(t)\cdot(1 − D_i(t)) + Y_{1i}(t)\cdot D_i(t)$$



$D$ only equals 1, when $T$ equals 1, so we never observe $Y_0i(1)$ for the treated units. 

In words, we don't know what Lambeth's outcome would have been in the second period, had they not been treated.


## Average Treatment on Treated {.smaller}

Our goal is to estimate the average effect of treatment on treated (ATT):


$$\tau_{ATT} = E[Y_{1i}(1) -  Y_{0i}(1)|D=1]$$

That is, what would have happened in Lambeth, had their water company not moved their pipes


## Average Treatment on Treated {.smaller}

Our goal is to estimate the average effect of treatment on treated (ATT):

We we can observe is:

|               | Pre-Period (T=0)  | Post-Period (T=1)  |
|-|--|-|
| Treated $D_{i}=1$  |  $E[Y_{0i}(0)\vert D_i = 1]$ | $E[Y_{1i}(1)\vert D_i = 1]$  |
| Control $D_i=0$  |  $E[Y_{0i}(0)\vert D_i = 0]$ | $E[Y_{0i}(1)\vert D_i = 0]$  |


## Data {.smaller}

Because potential outcomes notation is abstract, let's consider a modified description of the Snow's cholera death data from [Scott Cunningham](https://mixtape.scunning.com/difference-in-differences.html):

```{r}
#| label = "choleradat",
#| echo = F
snow <- tibble(Company = c("Lambeth (D=1)", "Southwark and Vauxhall (D=0)"),
               `1849 (T=0)` = c(85,135),
               `1854 (T=1)` = c(19,147),

               )

knitr::kable(snow)

```


## How can we estimate the effect of moving pumps upstream? {.smaller}

Recall, our goal is to estimate the effect of the the treatment on the treated:

$$\tau_{ATT} = E[Y_{1i}(1) -  Y_{0i}(1)|D=1]$$

Let's conisder some strategies Snow could take to estimate this quantity:


## Before vs after comparisons:{.smaller}

:::{.nonincremental}
- Snow could have compared Labmeth in 1854 $(E[Y_i(1)|D_i = 1] = 19)$ to Lambeth in 1849 $(E[Y_i(0)|D_i = 1]=85)$, and claimed that moving the pumps upstream led to **66 fewer cholera deaths.** 

- Assumes Lambeth's pre-treatment outcomes in 1849 are a good proxy for what its outcomes would have been in 1954 if the pumps hadn't moved $(E[Y_{0i}(1)|D_i = 1])$.

- A skeptic might argue that Lambeth in 1849 $\neq$ Lambeth in 1854


```{r}
#| echo: false
knitr::kable(snow) |> 
  kable_styling() |> 
  row_spec(1, bold=T,color = "blue")
```

:::


## Treatment-Control comparisons in the Post Period. {.smaller}

:::{.nonincremental}

- Snow could have compared outcomes between Lambeth and S&V in 1954  ($E[Yi(1)|Di = 1] − E[Yi(1)|Di = 0]$), concluding that the change in pump locations led to **128 fewer deaths.**

- Here the assumption is that the outcomes in S&V and in 1854 provide a good proxy for what would have happened in Lambeth in 1954 had the pumps not been moved $(E[Y_{0i}(1)|D_i = 1])$

- Again, our skeptic could argue  Lambeth $\neq$ S&V 

```{r}
#| echo: false
knitr::kable(snow) |> 
  kable_styling() |> 
  kableExtra::column_spec(3, bold=T, color="red")
```

:::

## Difference in Differences {.smaller}

:::{.nonincremental}
To address these concerns, Snow employed what we now call a [difference-in-differences]{.blue} design, 

There are two, equivalent ways to view this design. 

$$\underbrace{\{E[Y_{i}(1)|D_{i} = 1] − E[Y_{i}(1)|D_{i} = 0]\}}_{\text{1. Treat-Control |Post }}− \overbrace{\{E[Y_{i}(0)|D_{i} = 1] − E[Y_{i}(0)|D_{i}=0 ]}^{\text{Treated-Control|Pre}}$$


- Difference 1: Average change between Treated and Control  in Post Period

- Difference 2: Average change between Treated and Control  in Pre Period

:::

## Difference in Differences {.smaller}

:::{.nonincremental}

$$\underbrace{\{E[Y_{i}(1)|D_{i} = 1] − E[Y_{i}(1)|D_{i} = 0]\}}_{\text{1. Treat-Control |Post }}− \overbrace{\{E[Y_{i}(0)|D_{i} = 1] − E[Y_{i}(0)|D_{i}=0 ]}^{\text{Treated-Control|Pre}}$$
Is equivalent to: 

$$\underbrace{\{E[Y_{i}(1)|D_{i} = 1] − E[Y_{i}(0)|D_{i} = 1]\}}_{\text{Post - Pre |Treated }}− \overbrace{\{E[Y_{i}(1)|D_{i} = 0] − E[Y_{i}(0)|D_{i}=0 ]}^{\text{Post-Pre|Control}}$$


- Difference 1: Average change between Treated over time
- Difference 2: Average change between Control over time

:::

## Difference in Differences {.smaller}


You'll see the DiD design represented both ways, but they produce the same result:

$$
\tau_{ATT} = (19-147) - (85-135) = -78
$$

$$
\tau_{ATT} = (19-85) - (147-135) = -78
$$


## Identifying Assumption of a Difference in Differences Design {.smaller}

The key assumption in this design is what's known as the parallel trends assumption: $E[Y_{0i}(1) − Y_{0i}(0)|D_i = 1] = E[Y_{0i}(1) − Y_{0i}(0)|D_i = 0]$ 

- In words: If Lambeth hadn't moved its pumps, it would have followed a similar path as S&V

## Parallel Trends

```{r}
#| label: paralleltrends
#| echo: false

snow_g <- tibble(
  Period = c(0,0,3,3,0,3),
  Treatment = c(0,1,0, 1,1,1),
  Line = c(1,1,1,1,2,2),
  Company = c("S&V","Lambeth","S&V","Lambeth","Lambeth (D=0)","Lambeth (D=0)"),
  Deaths = c(135,85,147,19,85,97)
)

line_df <- tibble(
  line_type = c("solid","solid","dotted","dotted","solid","solid"),
  line_col = c("red","red","red","red","blue","blue")
)

snow_g %>%
  ggplot(aes(Period,Deaths, col=Company))+
  geom_point()+
  geom_line(linetype=line_df$line_type
            )+
  scale_color_manual(values = c("red","red","blue"))+
  geom_segment(aes(x=3.1,xend=3.1,y=19,yend=147), linetype = 2, col= "gray")+
  annotate(geom="text",x = 3.3,y=125, label = "1",hjust=.5)+
  geom_segment(aes(x=3.2,xend=3.2,y=19,yend=97), linetype = 2,col="gray")+
  annotate(geom="text",x = 3.3,y=55, label = "3",hjust=-.5)+
  geom_segment(aes(x=-.1,xend=-.1,y=85,yend=135), linetype = 2,col="gray")+
  annotate(geom="text",x = -.1,y=120, label = "2",hjust=1.5)+
  xlim(-2,6)+
  scale_x_continuous(breaks = c(0,3),labels = c("Pre","Post"))+
  theme_bw() -> snow_p

snow_p


```

## Using linear regression to estimate a Difference in Difference {.smaller}

:::: panel-tabset

## Concept

- Recall that linear regression provides a...
  - linear estimate of the conditional expectation function
- In the canonincal pre-post, treated and control DiD, $\beta_3$ from the following linear regression will give us the ATT:

:::{.fragment}

$$
y = \beta_0 + \beta_1 Post + \beta_2 Treated + \underbrace{\beta_3Post\times Treated}_{\tau_{ATT}}
$$

:::

## Code

```{r}
#| echo: true
#| label: didcode

cholera_df <- tibble(
  Period = factor(c("Pre","Pre","Post","Post"),
                  levels = c("Pre","Post")),
  Year = c(1849,1849, 1854,1854),
  Treated = factor(c("Control","Treated","Control","Treated")),
  Company = c("S&V","Lambeth","S&V","Lambeth"),
  Deaths = c(135,85,147,19)
)

m_did <- lm(Deaths~Period + Treated + Period:Treated, cholera_df)

m_did

```

## Data

```{r}
#| echo: false
#| label: diddata


DT::datatable(cholera_df)
```


## DiD

```{r}
#| echo: false
#| results: asis
#| label: didtab

texreg::htmlreg(m_did,
                custom.coef.names = c("(Intercept)",
                                      "Post (1854)",
                                      "Treated (Lambeth)",
                                      "Post X Treated (DID)")
                )
```

## Figure

```{r}
#| echo: false
#| label: didfig


snow_g %>%
  ggplot(aes(Period,Deaths,col = Company))+
  geom_point()+
  geom_line()+
  xlim(-1,4)+
  annotate(geom = "text", x = 0, y = 135,
           label = expression(beta[0]), hjust=0.5, vjust =-.5)+
  geom_segment(aes(x=0, xend = 3, y=135, yend=135), 
               linetype = 1, col ="gray30",
               arrow = arrow(length = unit(0.01, "npc")))+
  geom_segment(aes(x=3, xend = 3, y=135, yend=147), 
               linetype = 1, col ="gray30",
               arrow = arrow(length = unit(0.01, "npc")))+
  annotate(geom = "text", x = 3, y = 141,
           label = expression(beta[1]), hjust=-0.5, vjust =0.5,
           col = "gray30") +
  geom_segment(aes(x=3.2, xend = 3.2, y=147, yend=97), 
               linetype = 1, col ="gray50",
               arrow = arrow(length = unit(0.01, "npc")))+
  annotate(geom = "text", x = 3, y = 122.5,
           label = expression(beta[2]), hjust=-0.5, vjust =0.5,col = "gray50")+
  geom_segment(aes(x=3, xend = 3, y=97, yend=19), 
               linetype = 1, col ="gray70",
               arrow = arrow(length = unit(0.01, "npc")))+
  annotate(geom = "text", x = 3, y = 58,
           label = expression(beta[3]), hjust=-0.5, vjust =0.5,col = "gray70")+
  scale_x_continuous(breaks = c(0,3),labels = c("Pre","Post"))+
  theme_bw() -> did_p

did_p

```







:::{.nonincremental}

- $\beta_0=$ Outcome in control (S&V) before treatment
- $\beta_1=$ Fixed, [unit invariant]{.blue} differences between [pre]{.blue} and [post]{.blue} periods
- $\beta_2=$ Fixed, [time invariant]{.blue} differences between [treated]{.blue} and [control]{.blue}
- $\beta_3=$ [Difference-in-Differences]{.blue} = $E[Y_{1i}(1) -  Y_{0i}(1)|D=1]$

:::

::::


## Summary {.smaller}

- A [Difference in Differences]{.blue} (DiD, or diff-in-diff) design combines a pre-post comparison, with a treated and control comparison
  
- Differencing twice accounts for fixed differences [across units]{.blue} and [between periods]{.blue}
  - But not time varying differences across units...
  
- The key identifying assumption of a DiD design is the assumption of [parallel trends]{.blue}
  - Absent treatment, treated and control groups
would see the same changes over time.
  - Hard to prove, possible to assess if we have multiple periods of pre-treatment observations



## Generalizing Diff-in-Diff with Linear Regression {.smaller}



- Linear regression allows us to generalizes Diff-in-Diff to multiple periods and treatment interventions, with [fixed effects]{.blue}

:::{.fragment}
$$
y_{it} = \overbrace{\alpha_i}^{\text{Unit FE}} + \underbrace{\gamma_t}_{\text{Period FE}} + \overbrace{\tau*d_{it}}^{\text{Treatment}} + \underbrace{X\beta}_{\text{Covariates}} + \epsilon_{it}
$$
:::

  - [Unit fixed effects]{.blue} $(\alpha_i)$control for time-invariant differences across units
  - [Period fixed effects]{.blue} $(\gamma_i)$ control for unit-invariant differences across periods
  - [$\tau$]{.blue} corresponds the [Difference-in-Difference]{.blue} estimate for a [two-way fixed effects]{.blue} regression

## Extensions and limitations{.smaller}

- Interpretation of [two-way fixed effects]{.blue} DiD estimator is [complicated]{.blue}...
  - @Goodman-Bacon2021-ah
  - @Callaway2021-av
- More pre-treatment periods allow you assess "parallel trends" assumption
- Alternative methods 
  - Synthetic control
  - Event Study Designs
- What if you have multiple treatments or treatments that come and go?
  - Panel Matching
  - Generalized Synthetic control


## Applications{.smaller}

- [Card and Krueger (1994)](https://www.nber.org/papers/w4509) What effect did raising the minimum wage in NJ have on employment

- [Abadie, Diamond, & Hainmueller (2014)](https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12116?casa_token=_ceCu4SwzTEAAAAA%3AP9aeaZpT_Zh1VdWKXx_tEmzaJTtMJ1n0eG7EaYlvJZYN000re33cfMAI2O8N8htFJjOsln2GyVeQql4) What effect did German Unification have on economic development in West Germany

- [Malesky, Nguyen and Tran (2014)](https://www.cambridge.org/core/journals/american-political-science-review/article/impact-of-recentralization-on-public-services-a-differenceindifferences-analysis-of-the-abolition-of-elected-councils-in-vietnam/3477854BAAFE152DC93C594169D64F58) How does decentralization influence public services?



# {{< fa code>}} Previewing Lab 7 {.inverse}

## Replicating Grumbach and Hill (2022)

- In this week's lab, we'll be conducting a partial replication of @Grumbach2022-zj [“Rock the Registration: Same Day Registration Increases Turnout of Young Voters.”](../files/readings/grumbach_hill_2021.pdf)

- On Thursday, we'll walk through 
  - the paper's design and argument
  - setting up and exploring the data
  - reproducing some descriptive figures

- Next Thursday, we'll focus on replicating and understanding the main results

##

![](images/07_grumbach2022.png)

## General Structure of Labs 7-8

Lab 7:

- Summarize the study
- Download and load the data
- Recode the data
- Merge the data
- Recreate Figures 1 and 2

Lab 8:

- Estimate some baseline models to understand Two-Way Fixed Effects
- Estimate some of the models in Figure 3
- Extend the study, perhaps considering SDR by race or gender

## Reading Grumbach and Hill (2022){.smaller}

Reading @Grumbach2022-zj, focus on being able to answer the following:

- What's the research question? 
  - General RQ: First sentence, second paragraph, p. 405
  - Specific RQs: p. 405-406

- What's the theoretical framework?
  - Intro and Theory of Registration, p. 407-409

- What's the empirical design?
  - Methods pp. 409-410
- What's are the main results?
  - Results pp. 410-413
  - Figure 3 in particular

## Q1: Download the replication files

Rather than downloading the files directly from the paper's [replication archives]{.blue}, in this lab, we will [download the replication files]{.blue} to your computers and then [load the data]{.blue} into R from [where they're saved]{.blue}

Please click [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/AW5LU8) and let's download the files together.



## 1. Go to the paper's dataverse

Please click [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/AW5LU8)

![](images/07_rep1.png)

## 2. Log in through Brown

![](images/07_rep2.png)


## 3. Select all of the files

Make sure to **Select all 11 files in this dataset**

![](images/07_rep3.png)

![](images/07_rep4.png)

## 4. Download the files in their original format

![](images/07_rep5.png)

##
### 5. Save and unzip the downloaded files into your course folder where your labs are saved

![](images/07_rep6.png)

## Q3: Load the data into R {.smaller}

If you've saved the dataverse_files [into the folder where your lab is saved]{.blue}, you should be able to run the following code after [setting the working directory]{.blue} to [source file location]{.blue}:

```{r}
#| eval: false
#| echo: true

# Remember to set working directory:
# Session > Set working directory > Source file location

# Load fips_codes
fips_codes <- read_csv("dataverse_files/fips_codes_website.csv")%>%
  janitor::clean_names()

# Load policy data
data <- readRDS("dataverse_files/policy_data_updated.RDS")%>%
  janitor::clean_names()

# Load CPS data
cps <- read_csv("dataverse_files/cps_00021.csv") %>%
  janitor::clean_names()
```


# {{< fa home >}} Summary {.inverse}

## Summary



## References